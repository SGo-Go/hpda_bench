{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anlyse [`HiBench`](https://github.com/Intel-bigdata/HiBench) Measurements on [Gilgamesh](https://kb.hlrs.de/platforms/index.php/Urika_GX) (Cray URIKA GX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get access to Mesos monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: To track the usage of Gilgamesh nodes, open http://127.0.0.1:5050/ in the [about:profiles](Gilgamesh profile). Authentificate with your username and password: `less /security/secrets/$USER.mesos`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh gilgamesch 'echo -e \" login:$(whoami)\\npasswd:$(cat /security/secrets/$USER.mesos)\"' 2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up old measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bind: Address already in use\n",
      "channel_setup_fwd_listener_tcpip: cannot listen to port: 8080\n",
      "Could not request local forwarding.\n"
     ]
    }
   ],
   "source": [
    "!ssh gilgamesch 'rm -rf report/hibench.report' #2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "measurements_loacal_folder = os.path.join('.', 'data_x')\n",
    "plotting_metric='throughput' # 'elapsed_time'\n",
    "save_plots_to_file = \"hibench-gilgamesh.html\" # None # if none embed in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition & Wrangling: Get data from multiple reports on cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy results to local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$measurements_loacal_folder\"\n",
    "# rm -rf ./data/*\n",
    "mkdir -p $1\n",
    "scp gilgamesch:~/proj/hidalgo/wp3/soft/HiBench/report/summary/hibench*.report $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and wrangle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import io\n",
    "import pandas\n",
    "\n",
    "def read_hibench_report(filename, scale, ncores):\n",
    "    recent_measurements = pandas.read_csv(filename, sep=\"\\s+\")\n",
    "    recent_measurements.rename(columns={\"Type\" : \"name\", \"Input_data_size\" : \"data_size\", \"Duration(s)\": \"duration\", \"Throughput(bytes/s)\":\"throughput\", \"Throughput/node\":\"node_throughput\"}, inplace=True)\n",
    "    recent_measurements.insert(1, 'scale', scale)\n",
    "    recent_measurements.insert(2, 'ncores', ncores)\n",
    "    recent_measurements['throughput'] = recent_measurements['throughput']/(1024**2) # convert B/s to MB/s\n",
    "    recent_measurements['data_size'] = recent_measurements['data_size']/(1024**2) # convert B to MB\n",
    "    return recent_measurements\n",
    "\n",
    "re_filename = re.compile(\"hibench-(?P<scale>.+)-(?P<ncores>[0-9]+)\\.report\")\n",
    "measurements = None\n",
    "for file in os.listdir(measurements_loacal_folder):\n",
    "    match_filename = re_filename.match(file)\n",
    "    if match_filename:\n",
    "        recent_measurements = read_hibench_report(os.path.join(measurements_loacal_folder, match_filename.group(0)),\n",
    "                                                  match_filename.group('scale'), int(match_filename.group('ncores')))\n",
    "        if measurements is None:\n",
    "            measurements = recent_measurements\n",
    "        else:\n",
    "            measurements = measurements.append( recent_measurements, ignore_index=True )\n",
    "# measurements = measurements.groupby(['scale','name','ncores'], as_index=False).agg({'duration':'mean', 'data_size':'mean', 'throughput':'mean', 'node_throughput':'mean'})\n",
    "# measurements[measurements.scale=='gigantic'].sort_values(by=['name']).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot elapsed time and speedup (in [`bokeh`](https://docs.bokeh.org/en/latest/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ppn = 36\n",
    "\n",
    "elapsedtime_metric = lambda df: df['duration']\n",
    "memory_metric = lambda df: df['ram']\n",
    "io_metric = lambda df: df['io_in']+df['io_out']\n",
    "def speedup_metric(df):\n",
    "    \"\"\"Semi-speedup\"\"\"\n",
    "    min_raw = df.loc[df['ncores'].idxmin()]\n",
    "    return (min_raw['duration']*min_raw['ncores'])/df['duration']\n",
    "def node_speedup_metric(df):\n",
    "    \"\"\"Semi-speedup\"\"\"\n",
    "    min_raw = df[df['ncores']==cluster_ppn].iloc[0]\n",
    "    return (min_raw['duration']*min_raw['ncores'])/df['duration']\n",
    "def efficiency_metric(df):\n",
    "    \"\"\"Semi-efficiency\"\"\"\n",
    "    min_raw = df.loc[df['ncores'].idxmin()]\n",
    "    return (min_raw['duration']*min_raw['ncores'])/df['duration']/df['ncores']\n",
    "def node_efficiency_metric(df):\n",
    "    \"\"\"Semi-efficiency\"\"\"\n",
    "    min_raw = df[df['ncores']==cluster_ppn].iloc[0]\n",
    "    return (min_raw['duration']*min_raw['ncores'])/df['duration']/df['ncores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file\n",
    "from bokeh.models import Range1d, axes\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.layouts import Row, Column, gridplot\n",
    "# output_notebook() # redundant in Jupyter Lab\n",
    "\n",
    "from bokeh.palettes import Dark2_5 as palette\n",
    "import itertools \n",
    "\n",
    "if not save_plots_to_file: output_notebook() # uncomment if wish to \n",
    "\n",
    "def scaling_plot(measurements, axis_type='linear', y_axis_data = ('throughput', 'Throughput, MB/s')): #'log', ('duration', 'Duration, s')\n",
    "    y_axis_field, y_axis_label = y_axis_data\n",
    "\n",
    "    row = measurements.iloc[0]\n",
    "    title = 'HiBench.{name} test'.format(name=row['name'])\n",
    "\n",
    "    # Plot some metric for all measurements\n",
    "    colors = itertools.cycle(palette)\n",
    "    fig = figure(title=title, sizing_mode='scale_width', y_axis_type=axis_type, x_axis_type=axis_type,)\n",
    "\n",
    "    fig.grid.grid_line_alpha = 0.75\n",
    "    fig.ygrid.band_fill_color = \"olive\"\n",
    "    fig.ygrid.band_fill_alpha = 0.1\n",
    "\n",
    "    min_ncores, max_ncores=measurements['ncores'].min(), measurements['ncores'].max()\n",
    "    fig.xaxis.axis_label = '# of cores'\n",
    "    fig.xaxis.ticker = measurements.ncores\n",
    "    fig.x_range = Range1d(0, max_ncores+cluster_ppn)\n",
    "    fig.extra_x_ranges = {\"ClusterNodes\": Range1d(start=0, end=max_ncores/cluster_ppn+1)}\n",
    "    fig.add_layout(axes.LinearAxis(x_range_name=\"ClusterNodes\", axis_label=\"# of nodes\", ticker = measurements.ncores/cluster_ppn), 'above')\n",
    "\n",
    "    fig.yaxis.axis_label = y_axis_label\n",
    "\n",
    "    metric=elapsedtime_metric\n",
    "    for label, measurements_scale in measurements.groupby('scale'):\n",
    "        color = next(colors)\n",
    "        legend=measurements_scale['scale'].iloc[0]\n",
    "        fig.line(measurements_scale['ncores'], measurements_scale[y_axis_field], color=color, legend=legend)\n",
    "        fig.circle(measurements_scale['ncores'], measurements_scale[y_axis_field], color=color, fill_color='white', size=6, legend=legend)\n",
    "\n",
    "    fig.legend.location = \"bottom_right\"\n",
    "    return fig\n",
    "\n",
    "# List of plotting functions for popular metrics\n",
    "elapsed_time_plotting_function = lambda measurements: scaling_plot(measurements, 'log', ('duration', 'Duration, s'))\n",
    "# speedup_plotting_function = lambda measurements: scaling_plot(measurements, 'linear', ('speedup', 'Speedup, s'))\n",
    "throughput_plotting_function =  lambda measurements: scaling_plot(measurements, 'linear', ('throughput', 'Throughput, MB/s'))\n",
    "\n",
    "plotting_function = eval(\"{}_plotting_function\".format(plotting_metric))\n",
    "plots_table = measurements\\\n",
    "            .groupby(['scale','name','ncores'], as_index=False).agg({'duration':'mean', 'data_size':'mean', 'throughput':'mean', 'node_throughput':'mean'})\\\n",
    "            .groupby(['name'])['scale', 'name', 'ncores', 'duration', 'throughput'].apply(plotting_function)\n",
    "\n",
    "names = ['LinearRegression', 'LogisticRegression', 'PCA', 'SVD', 'ScalaSparkAggregation', 'ScalaSparkJoin', 'ScalaSparkSort', 'ScalaSparkTerasort']\n",
    "# names = measurements['name'].unique() # for all plots uncomment this line\n",
    "\n",
    "from toolz import partition_all\n",
    "L = plots_table.loc[names].values.tolist()\n",
    "grid = list(partition_all(2, L))\n",
    "\n",
    "if save_plots_to_file: output_file(save_plots_to_file, title=\"HiBench results on Gilgamesh\")\n",
    "show(gridplot(grid, plot_width=400, plot_height=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save profiles in CSV/Org-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_column_name(name):\n",
    "    re_col_name=re.compile(r\"\\(\\'([a-zA-Z0-9]+)\\', (\\'([a-zA-Z]+)\\'\\)|[0-9]+)\")\n",
    "    m = re_col_name.match(name)\n",
    "    if m: return \"{1}\".format(m.group(1),m.group(2))\n",
    "    return name\n",
    "\n",
    "def to_profile_tables(df, filed='duration'):\n",
    "    df_profile = pandas.DataFrame(df.pivot_table(index=['name'],#['name', 'data_size'],\n",
    "                                                 columns='ncores', values=['duration']).to_records())\n",
    "    df_profile.columns = map(fix_column_name, df_profile.columns)\n",
    "    return df_profile\n",
    "\n",
    "measurements = measurements.groupby(['scale','name','ncores'], as_index=False).agg({'duration':'mean', 'data_size':'mean', 'throughput':'mean', 'node_throughput':'mean'})\n",
    "\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "for scale in measurements['scale'].unique():\n",
    "    df_profile = to_profile_tables(pandas.DataFrame(measurements[measurements['scale'] == scale]))\n",
    "#     print(display(HTML(df_profile.to_html())))\n",
    "    df_profile.to_csv('/home/hpcgogol/proj/hidalgo/doc/D3.3/figs/%s.org' % scale, index_label=False, sep='|', header=True,\n",
    "                      line_terminator='|' + os.linesep, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
